"use strict";
/**
 * @license
 * Copyright 2018 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * =============================================================================
 */
var __extends = (this && this.__extends) || (function () {
    var extendStatics = function (d, b) {
        extendStatics = Object.setPrototypeOf ||
            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };
        return extendStatics(d, b);
    };
    return function (d, b) {
        extendStatics(d, b);
        function __() { this.constructor = d; }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
})();
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (_) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
Object.defineProperty(exports, "__esModule", { value: true });
var tf = require("@tensorflow/tfjs-core");
var seedrandom = require("seedrandom");
var deep_clone_1 = require("../util/deep_clone");
var deep_map_1 = require("../util/deep_map");
var growing_ring_buffer_1 = require("../util/growing_ring_buffer");
var ring_buffer_1 = require("../util/ring_buffer");
// Here we implement a simple asynchronous iterator.
// This lets us avoid using either third-party stream libraries or
// recent TypeScript language support requiring polyfills.
/**
 * Create a `LazyIterator` from an array of items.
 */
function iteratorFromItems(items) {
    return new ArrayIterator(items);
}
exports.iteratorFromItems = iteratorFromItems;
/**
 * Create a `LazyIterator` of incrementing integers.
 */
function iteratorFromIncrementing(start) {
    var i = start;
    return iteratorFromFunction(function () { return ({ value: i++, done: false }); });
}
exports.iteratorFromIncrementing = iteratorFromIncrementing;
/**
 * Create a `LazyIterator` from a function.
 *
 * ```js
 * let i = -1;
 * const func = () =>
 *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};
 * const iter = tf.data.iteratorFromFunction(func);
 * await iter.forEachAsync(e => console.log(e));
 * ```
 *
 * @param func A function that produces data on each call.
 */
function iteratorFromFunction(func) {
    return new FunctionCallIterator(func);
}
exports.iteratorFromFunction = iteratorFromFunction;
/**
 * Create a `LazyIterator` by concatenating underlying streams, which are
 * themselves provided as a stream.
 *
 * This can also be thought of as a "stream flatten" operation.
 *
 * @param baseIterators A stream of streams to be concatenated.
 * @param baseErrorHandler An optional function that can intercept `Error`s
 *   raised during a `next()` call on the base stream.  This function can decide
 *   whether the error should be propagated, whether the error should be
 *   ignored, or whether the base stream should be terminated.
 */
function iteratorFromConcatenated(baseIterators, baseErrorHandler) {
    return new ChainedIterator(baseIterators, baseErrorHandler);
}
exports.iteratorFromConcatenated = iteratorFromConcatenated;
/**
 * Create a `LazyIterator` by concatenating streams produced by calling a
 * stream-generating function a given number of times.
 *
 * Since a `LazyIterator` is read-once, it cannot be repeated, but this
 * function can be used to achieve a similar effect:
 *
 *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);
 *
 * @param iteratorFunc: A function that produces a new stream on each call.
 * @param count: The number of times to call the function.
 * @param baseErrorHandler An optional function that can intercept `Error`s
 *   raised during a `next()` call on the base stream.  This function can decide
 *   whether the error should be propagated, whether the error should be
 *   ignored, or whether the base stream should be terminated.
 */
function iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {
    return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);
}
exports.iteratorFromConcatenatedFunction = iteratorFromConcatenatedFunction;
/**
 * Create a `LazyIterator` by zipping together an array, dict, or nested
 * structure of `LazyIterator`s (and perhaps additional constants).
 *
 * The underlying streams must provide elements in a consistent order such
 * that they correspond.
 *
 * Typically, the underlying streams should have the same number of
 * elements. If they do not, the behavior is determined by the
 * `mismatchMode` argument.
 *
 * The nested structure of the `iterators` argument determines the
 * structure of elements in the resulting iterator.
 *
 * @param iterators: An array or object containing LazyIterators at the
 * leaves.
 * @param mismatchMode: Determines what to do when one underlying iterator
 * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)
 * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`
 * causes the zipped iterator to terminate with the furst underlying
 * streams, so elements remaining on the longer streams are ignored.
 * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling
 * in nulls for the exhausted streams, until all streams are exhausted.
 */
function iteratorFromZipped(iterators, mismatchMode) {
    if (mismatchMode === void 0) { mismatchMode = ZipMismatchMode.FAIL; }
    return new ZipIterator(iterators, mismatchMode);
}
exports.iteratorFromZipped = iteratorFromZipped;
/**
 * An asynchronous iterator, providing lazy access to a potentially
 * unbounded stream of elements.
 *
 * Iterator can be obtained from a dataset:
 * `const iter = await dataset.iterator();`
 */
var LazyIterator = /** @class */ (function () {
    function LazyIterator() {
    }
    /**
     * Collect all remaining elements of a bounded stream into an array.
     * Obviously this will succeed only for small streams that fit in memory.
     * Useful for testing.
     *
     * @returns A Promise for an array of stream elements, which will resolve
     *   when the stream is exhausted.
     */
    LazyIterator.prototype.toArray = function () {
        return __awaiter(this, void 0, void 0, function () {
            var result, x;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        result = [];
                        return [4 /*yield*/, this.next()];
                    case 1:
                        x = _a.sent();
                        _a.label = 2;
                    case 2:
                        if (!!x.done) return [3 /*break*/, 4];
                        result.push(x.value);
                        return [4 /*yield*/, this.next()];
                    case 3:
                        x = _a.sent();
                        return [3 /*break*/, 2];
                    case 4: return [2 /*return*/, result];
                }
            });
        });
    };
    /**
     * Collect all elements of this dataset into an array with prefetching 100
     * elements. This is useful for testing, because the prefetch changes the
     * order in which the Promises are resolved along the processing pipeline.
     * This may help expose bugs where results are dependent on the order of
     * Promise resolution rather than on the logical order of the stream (i.e.,
     * due to hidden mutable state).
     *
     * @returns A Promise for an array of stream elements, which will resolve
     *   when the stream is exhausted.
     */
    LazyIterator.prototype.toArrayForTest = function () {
        return __awaiter(this, void 0, void 0, function () {
            var stream, result, x;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        stream = this.prefetch(100);
                        result = [];
                        return [4 /*yield*/, stream.next()];
                    case 1:
                        x = _a.sent();
                        _a.label = 2;
                    case 2:
                        if (!!x.done) return [3 /*break*/, 4];
                        result.push(x.value);
                        return [4 /*yield*/, stream.next()];
                    case 3:
                        x = _a.sent();
                        return [3 /*break*/, 2];
                    case 4: return [2 /*return*/, result];
                }
            });
        });
    };
    /**
     * Draw items from the stream until it is exhausted.
     *
     * This can be useful when the stream has side effects but no output.  In
     * that case, calling this function guarantees that the stream will be
     * fully processed.
     */
    LazyIterator.prototype.resolveFully = function () {
        return __awaiter(this, void 0, void 0, function () {
            var x;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, this.next()];
                    case 1:
                        x = _a.sent();
                        _a.label = 2;
                    case 2:
                        if (!!x.done) return [3 /*break*/, 4];
                        return [4 /*yield*/, this.next()];
                    case 3:
                        x = _a.sent();
                        return [3 /*break*/, 2];
                    case 4: return [2 /*return*/];
                }
            });
        });
    };
    /**
     * Draw items from the stream until it is exhausted, or a predicate fails.
     *
     * This can be useful when the stream has side effects but no output.  In
     * that case, calling this function guarantees that the stream will be
     * fully processed.
     */
    LazyIterator.prototype.resolveWhile = function (predicate) {
        return __awaiter(this, void 0, void 0, function () {
            var x, shouldContinue;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, this.next()];
                    case 1:
                        x = _a.sent();
                        shouldContinue = predicate(x.value);
                        _a.label = 2;
                    case 2:
                        if (!((!x.done) && shouldContinue)) return [3 /*break*/, 4];
                        return [4 /*yield*/, this.next()];
                    case 3:
                        x = _a.sent();
                        shouldContinue = predicate(x.value);
                        return [3 /*break*/, 2];
                    case 4: return [2 /*return*/];
                }
            });
        });
    };
    /**
     * Handles errors thrown on this stream using a provided handler function.
     *
     * @param handler A function that handles any `Error` thrown during a `next()`
     *   call and returns true if the stream should continue (dropping the failed
     *   call) or false if the stream should quietly terminate.  If the handler
     *   itself throws (or rethrows) an `Error`, that will be propagated.
     *
     * @returns A `LazyIterator` of elements passed through from upstream,
     *   possibly filtering or terminating on upstream `next()` calls that
     *   throw an `Error`.
     */
    LazyIterator.prototype.handleErrors = function (handler) {
        return new ErrorHandlingLazyIterator(this, handler);
    };
    // TODO(soergel): Implement reduce() etc.
    /**
     * Filters this stream according to `predicate`.
     *
     * @param predicate A function mapping a stream element to a boolean or a
     * `Promise` for one.
     *
     * @returns A `LazyIterator` of elements for which the predicate was true.
     */
    LazyIterator.prototype.filter = function (predicate) {
        return new FilterIterator(this, predicate);
    };
    /**
     * Maps this stream through a 1-to-1 transform.
     *
     * @param transform A function mapping a stream element to a transformed
     *   element.
     *
     * @returns A `LazyIterator` of transformed elements.
     */
    LazyIterator.prototype.map = function (transform) {
        return new MapIterator(this, transform);
    };
    /**
     * Maps this stream through an async 1-to-1 transform.
     *
     * @param transform A function mapping a stream element to a `Promise` for a
     *   transformed stream element.
     *
     * @returns A `LazyIterator` of transformed elements.
     */
    LazyIterator.prototype.mapAsync = function (transform) {
        return new AsyncMapIterator(this, transform);
    };
    /**
     * Maps this stream through a 1-to-1 transform, forcing serial execution.
     *
     * @param transform A function mapping a stream element to a transformed
     *   element.
     *
     * @returns A `LazyIterator` of transformed elements.
     */
    LazyIterator.prototype.serialMapAsync = function (transform) {
        return new AsyncMapIterator(this, transform).serial();
    };
    /**
     * Maps this stream through a 1-to-many transform.
     *
     * @param transform A function mapping a stream element to an array of
     *   transformed elements.
     *
     * @returns A `DataStream` of transformed elements.
     */
    LazyIterator.prototype.flatmap = function (transform) {
        return new FlatmapIterator(this, transform);
    };
    /**
     * Apply a function to every element of the stream.
     *
     * @param f A function to apply to each stream element.
     */
    LazyIterator.prototype.forEachAsync = function (f) {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                return [2 /*return*/, this.map(f).resolveFully()];
            });
        });
    };
    /**
     * Apply a function to every element of the stream, forcing serial execution.
     *
     * @param f A function to apply to each stream element.  Should return 'true'
     *   to indicate that the stream should continue, or 'false' to cause it to
     *   terminate.
     */
    LazyIterator.prototype.serialForEach = function (f) {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                return [2 /*return*/, this.serialMapAsync(f).resolveWhile(function (x) { return (x === true); })];
            });
        });
    };
    /**
     * Groups elements into batches, represented as arrays of elements.
     *
     * We can think of the elements of this iterator as 'rows' (even if they are
     * nested structures).  By the same token, consecutive values for a given
     * key within the elements form a 'column'.  This matches the usual sense of
     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).
     *
     * Thus, "Row-major" means that the resulting batch is simply a collection of
     * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major
     * form, which is needed for vectorized computation.
     *
     * @param batchSize The number of elements desired per batch.
     * @param smallLastBatch Whether to emit the final batch when it has fewer
     *   than batchSize elements. Default true.
     * @returns A `LazyIterator` of batches of elements, represented as arrays
     *   of the original element type.
     */
    LazyIterator.prototype.rowMajorBatch = function (batchSize, smallLastBatch) {
        if (smallLastBatch === void 0) { smallLastBatch = true; }
        return new RowMajorBatchIterator(this, batchSize, smallLastBatch);
    };
    /**
     * Groups elements into batches, represented in column-major form.
     *
     * We can think of the elements of this iterator as 'rows' (even if they are
     * nested structures).  By the same token, consecutive values for a given
     * key within the elements form a 'column'.  This matches the usual sense of
     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).
     *
     * Thus, "column-major" means that the resulting batch is a (potentially
     * nested) structure representing the columns.  Each column entry, then,
     * contains a collection of the values found in that column for a range of
     * input elements.  This representation allows for vectorized computation, in
     * contrast to the row-major form.
     *
     * The inputs should all have the same nested structure (i.e., of arrays and
     * dicts).  The result is a single object with the same nested structure,
     * where the leaves are arrays collecting the values of the inputs at that
     * location (or, optionally, the result of a custom function applied to those
     * arrays).
     *
     * @param batchSize The number of elements desired per batch.
     * @param smallLastBatch Whether to emit the final batch when it has fewer
     *   than batchSize elements. Default true.
     * @param zipFn: (optional) A function that expects an array of elements at a
     *   single node of the object tree, and returns a `DeepMapResult`.  The
     *   `DeepMapResult` either provides a result value for that node (i.e.,
     *   representing the subtree), or indicates that the node should be processed
     *   recursively.  The default zipFn recurses as far as possible and places
     *   arrays at the leaves.
     * @returns A `LazyIterator` of batches of elements, represented as an object
     *   with collections at the leaves.
     */
    LazyIterator.prototype.columnMajorBatch = function (batchSize, smallLastBatch, 
    // tslint:disable-next-line:no-any
    zipFn) {
        if (smallLastBatch === void 0) { smallLastBatch = true; }
        if (zipFn === void 0) { zipFn = deep_map_1.zipToList; }
        // First collect the desired number of input elements as a row-major batch.
        var rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);
        // Now 'rotate' or 'pivot' the data, collecting all values from each column
        // in the batch (i.e., for each key within the elements) into an array.
        return rowBatches.map(function (x) { return deep_map_1.deepZip(x, zipFn); });
    };
    /**
     * Concatenate this `LazyIterator` with another.
     *
     * @param iterator A `LazyIterator` to be concatenated onto this one.
     * @param baseErrorHandler An optional function that can intercept `Error`s
     *   raised during a `next()` call on the base stream.  This function can
     *   decide whether the error should be propagated, whether the error should
     *   be ignored, or whether the base stream should be terminated.
     * @returns A `LazyIterator`.
     */
    LazyIterator.prototype.concatenate = function (iterator, baseErrorHandler) {
        return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);
    };
    /**
     * Limits this stream to return at most `count` items.
     *
     * @param count The maximum number of items to provide from the stream. If
     * a negative or undefined value is given, the entire stream is returned
     *   unaltered.
     */
    LazyIterator.prototype.take = function (count) {
        if (count < 0 || count == null) {
            return this;
        }
        return new TakeIterator(this, count);
    };
    /**
     * Skips the first `count` items in this stream.
     *
     * @param count The number of items to skip.  If a negative or undefined
     * value is given, the entire stream is returned unaltered.
     */
    LazyIterator.prototype.skip = function (count) {
        if (count < 0 || count == null) {
            return this;
        }
        return new SkipIterator(this, count);
    };
    /**
     * Prefetch the first `bufferSize` items in this stream.
     *
     * Note this prefetches Promises, but makes no guarantees about when those
     * Promises resolve.
     *
     * @param bufferSize: An integer specifying the number of elements to be
     *   prefetched.
     */
    LazyIterator.prototype.prefetch = function (bufferSize) {
        return new PrefetchIterator(this, bufferSize);
    };
    // TODO(soergel): deep sharded shuffle, where supported
    /**
     * Randomly shuffles the elements of this stream.
     *
     * @param bufferSize: An integer specifying the number of elements from
     * this stream from which the new stream will sample.
     * @param seed: (Optional.) An integer specifying the random seed that
     * will be used to create the distribution.
     */
    LazyIterator.prototype.shuffle = function (windowSize, seed) {
        return new ShuffleIterator(this, windowSize, seed);
    };
    /**
     * Force an iterator to execute serially: each next() call will await the
     * prior one, so that they cannot execute concurrently.
     */
    LazyIterator.prototype.serial = function () {
        return new SerialIterator(this);
    };
    return LazyIterator;
}());
exports.LazyIterator = LazyIterator;
// ============================================================================
// The following private classes serve to implement the chainable methods
// on LazyIterator.  Unfortunately they can't be placed in separate files,
// due to resulting trouble with circular imports.
// ============================================================================
// Iterators that just extend LazyIterator directly
// ============================================================================
var ArrayIterator = /** @class */ (function (_super) {
    __extends(ArrayIterator, _super);
    function ArrayIterator(items) {
        var _this = _super.call(this) || this;
        _this.items = items;
        _this.trav = 0;
        return _this;
    }
    ArrayIterator.prototype.summary = function () {
        return "Array of " + this.items.length + " items";
    };
    ArrayIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var item;
            return __generator(this, function (_a) {
                if (this.trav >= this.items.length) {
                    return [2 /*return*/, { value: null, done: true }];
                }
                item = this.items[this.trav];
                this.trav++;
                return [2 /*return*/, { value: deep_clone_1.deepClone(item), done: false }];
            });
        });
    };
    return ArrayIterator;
}(LazyIterator));
var FunctionCallIterator = /** @class */ (function (_super) {
    __extends(FunctionCallIterator, _super);
    function FunctionCallIterator(nextFn) {
        var _this = _super.call(this) || this;
        _this.nextFn = nextFn;
        return _this;
    }
    FunctionCallIterator.prototype.summary = function () {
        return "Function call";
    };
    FunctionCallIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                try {
                    return [2 /*return*/, this.nextFn()];
                }
                catch (e) {
                    // Modify the error message but leave the stack trace intact
                    e.message =
                        "Error thrown while iterating through a dataset: " + e.message;
                    throw e;
                }
                return [2 /*return*/];
            });
        });
    };
    return FunctionCallIterator;
}(LazyIterator));
var SerialIterator = /** @class */ (function (_super) {
    __extends(SerialIterator, _super);
    function SerialIterator(upstream) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.lastRead = Promise.resolve({ value: null, done: false });
        return _this;
    }
    SerialIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> Serial";
    };
    SerialIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var _this = this;
            return __generator(this, function (_a) {
                // This sets this.lastRead to a new Promise right away, as opposed to
                // saying `await this.lastRead; this.lastRead = this.serialNext();` which
                // would not work because this.nextRead would be updated only after the
                // promise resolves.
                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });
                return [2 /*return*/, this.lastRead];
            });
        });
    };
    SerialIterator.prototype.serialNext = function () {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                return [2 /*return*/, this.upstream.next()];
            });
        });
    };
    return SerialIterator;
}(LazyIterator));
var SkipIterator = /** @class */ (function (_super) {
    __extends(SkipIterator, _super);
    function SkipIterator(upstream, maxCount) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.maxCount = maxCount;
        // Local state that should not be clobbered by out-of-order execution.
        _this.count = 0;
        _this.lastRead = Promise.resolve({ value: null, done: false });
        return _this;
    }
    SkipIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> Skip";
    };
    SkipIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var _this = this;
            return __generator(this, function (_a) {
                // This sets this.lastRead to a new Promise right away, as opposed to
                // saying `await this.lastRead; this.lastRead = this.serialNext();` which
                // would not work because this.nextRead would be updated only after the
                // promise resolves.
                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });
                return [2 /*return*/, this.lastRead];
            });
        });
    };
    SkipIterator.prototype.serialNext = function () {
        return __awaiter(this, void 0, void 0, function () {
            var skipped;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        if (!(this.count++ < this.maxCount)) return [3 /*break*/, 2];
                        return [4 /*yield*/, this.upstream.next()];
                    case 1:
                        skipped = _a.sent();
                        // short-circuit if upstream is already empty
                        if (skipped.done) {
                            return [2 /*return*/, skipped];
                        }
                        tf.dispose(skipped.value);
                        return [3 /*break*/, 0];
                    case 2: return [2 /*return*/, this.upstream.next()];
                }
            });
        });
    };
    return SkipIterator;
}(LazyIterator));
var TakeIterator = /** @class */ (function (_super) {
    __extends(TakeIterator, _super);
    function TakeIterator(upstream, maxCount) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.maxCount = maxCount;
        _this.count = 0;
        return _this;
    }
    TakeIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> Take";
    };
    TakeIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                if (this.count++ >= this.maxCount) {
                    return [2 /*return*/, { value: null, done: true }];
                }
                return [2 /*return*/, this.upstream.next()];
            });
        });
    };
    return TakeIterator;
}(LazyIterator));
// Note this batch just groups items into row-wise element arrays.
// Rotating these to a column-wise representation happens only at the dataset
// level.
var RowMajorBatchIterator = /** @class */ (function (_super) {
    __extends(RowMajorBatchIterator, _super);
    function RowMajorBatchIterator(upstream, batchSize, enableSmallLastBatch) {
        if (enableSmallLastBatch === void 0) { enableSmallLastBatch = true; }
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.batchSize = batchSize;
        _this.enableSmallLastBatch = enableSmallLastBatch;
        _this.lastRead = Promise.resolve({ value: null, done: false });
        return _this;
    }
    RowMajorBatchIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> RowMajorBatch";
    };
    RowMajorBatchIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var _this = this;
            return __generator(this, function (_a) {
                // This sets this.lastRead to a new Promise right away, as opposed to
                // saying `await this.lastRead; this.lastRead = this.serialNext();` which
                // would not work because this.nextRead would be updated only after the
                // promise resolves.
                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });
                return [2 /*return*/, this.lastRead];
            });
        });
    };
    RowMajorBatchIterator.prototype.serialNext = function () {
        return __awaiter(this, void 0, void 0, function () {
            var batch, item;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        batch = [];
                        _a.label = 1;
                    case 1:
                        if (!(batch.length < this.batchSize)) return [3 /*break*/, 3];
                        return [4 /*yield*/, this.upstream.next()];
                    case 2:
                        item = _a.sent();
                        if (item.done) {
                            if (this.enableSmallLastBatch && batch.length > 0) {
                                return [2 /*return*/, { value: batch, done: false }];
                            }
                            return [2 /*return*/, { value: null, done: true }];
                        }
                        batch.push(item.value);
                        return [3 /*break*/, 1];
                    case 3: return [2 /*return*/, { value: batch, done: false }];
                }
            });
        });
    };
    return RowMajorBatchIterator;
}(LazyIterator));
var FilterIterator = /** @class */ (function (_super) {
    __extends(FilterIterator, _super);
    function FilterIterator(upstream, predicate) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.predicate = predicate;
        _this.lastRead = Promise.resolve({ value: null, done: false });
        return _this;
    }
    FilterIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> Filter";
    };
    FilterIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var _this = this;
            return __generator(this, function (_a) {
                // This sets this.lastRead to a new Promise right away, as opposed to
                // saying `await this.lastRead; this.lastRead = this.serialNext();` which
                // would not work because this.nextRead would be updated only after the
                // promise resolves.
                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });
                return [2 /*return*/, this.lastRead];
            });
        });
    };
    FilterIterator.prototype.serialNext = function () {
        return __awaiter(this, void 0, void 0, function () {
            var item;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        if (!true) return [3 /*break*/, 2];
                        return [4 /*yield*/, this.upstream.next()];
                    case 1:
                        item = _a.sent();
                        if (item.done || this.predicate(item.value)) {
                            return [2 /*return*/, item];
                        }
                        tf.dispose(item.value);
                        return [3 /*break*/, 0];
                    case 2: return [2 /*return*/];
                }
            });
        });
    };
    return FilterIterator;
}(LazyIterator));
var MapIterator = /** @class */ (function (_super) {
    __extends(MapIterator, _super);
    function MapIterator(upstream, transform) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.transform = transform;
        return _this;
    }
    MapIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> Map";
    };
    MapIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var item, inputTensors, mapped, outputTensors, _i, inputTensors_1, t;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, this.upstream.next()];
                    case 1:
                        item = _a.sent();
                        if (item.done) {
                            return [2 /*return*/, { value: null, done: true }];
                        }
                        inputTensors = tf.tensor_util.getTensorsInContainer(item.value);
                        mapped = this.transform(item.value);
                        outputTensors = tf.tensor_util.getTensorsInContainer(mapped);
                        // TODO(soergel) faster intersection
                        // TODO(soergel) move to tf.disposeExcept(in, out)?
                        for (_i = 0, inputTensors_1 = inputTensors; _i < inputTensors_1.length; _i++) {
                            t = inputTensors_1[_i];
                            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {
                                t.dispose();
                            }
                        }
                        return [2 /*return*/, { value: mapped, done: false }];
                }
            });
        });
    };
    return MapIterator;
}(LazyIterator));
var ErrorHandlingLazyIterator = /** @class */ (function (_super) {
    __extends(ErrorHandlingLazyIterator, _super);
    function ErrorHandlingLazyIterator(upstream, handler) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.handler = handler;
        _this.count = 0;
        _this.lastRead = Promise.resolve({ value: null, done: false });
        return _this;
    }
    ErrorHandlingLazyIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> handleErrors";
    };
    ErrorHandlingLazyIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var _this = this;
            return __generator(this, function (_a) {
                // This sets this.lastRead to a new Promise right away, as opposed to
                // saying `await this.lastRead; this.lastRead = this.serialNext();` which
                // would not work because this.nextRead would be updated only after the
                // promise resolves.
                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });
                return [2 /*return*/, this.lastRead];
            });
        });
    };
    ErrorHandlingLazyIterator.prototype.serialNext = function () {
        return __awaiter(this, void 0, void 0, function () {
            var e_1;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        if (!true) return [3 /*break*/, 5];
                        _a.label = 1;
                    case 1:
                        _a.trys.push([1, 3, , 4]);
                        return [4 /*yield*/, this.upstream.next()];
                    case 2: return [2 /*return*/, _a.sent()];
                    case 3:
                        e_1 = _a.sent();
                        if (!this.handler(e_1)) {
                            return [2 /*return*/, { value: null, done: true }];
                        }
                        return [3 /*break*/, 4];
                    case 4: return [3 /*break*/, 0];
                    case 5: return [2 /*return*/];
                }
            });
        });
    };
    return ErrorHandlingLazyIterator;
}(LazyIterator));
var AsyncMapIterator = /** @class */ (function (_super) {
    __extends(AsyncMapIterator, _super);
    function AsyncMapIterator(upstream, transform) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.transform = transform;
        return _this;
    }
    AsyncMapIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> AsyncMap";
    };
    AsyncMapIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var item, inputTensors, mapped, outputTensors, _i, inputTensors_2, t;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, this.upstream.next()];
                    case 1:
                        item = _a.sent();
                        if (item.done) {
                            return [2 /*return*/, { value: null, done: true }];
                        }
                        inputTensors = tf.tensor_util.getTensorsInContainer(item.value);
                        return [4 /*yield*/, this.transform(item.value)];
                    case 2:
                        mapped = _a.sent();
                        outputTensors = tf.tensor_util.getTensorsInContainer(mapped);
                        // TODO(soergel) faster intersection
                        // TODO(soergel) move to tf.disposeExcept(in, out)?
                        for (_i = 0, inputTensors_2 = inputTensors; _i < inputTensors_2.length; _i++) {
                            t = inputTensors_2[_i];
                            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {
                                t.dispose();
                            }
                        }
                        return [2 /*return*/, { value: mapped, done: false }];
                }
            });
        });
    };
    return AsyncMapIterator;
}(LazyIterator));
// Iterators that maintain a queue of pending items
// ============================================================================
/**
 * A base class for transforming streams that operate by maintaining an
 * output queue of elements that are ready to return via next().  This is
 * commonly required when the transformation is 1-to-many:  A call to next()
 * may trigger a call to the underlying stream, which will produce many
 * mapped elements of this stream-- of which we need to return only one, so
 * we have to queue the rest.
 */
var OneToManyIterator = /** @class */ (function (_super) {
    __extends(OneToManyIterator, _super);
    function OneToManyIterator() {
        var _this = _super.call(this) || this;
        _this.outputQueue = new growing_ring_buffer_1.GrowingRingBuffer();
        _this.lastRead = Promise.resolve({ value: null, done: false });
        return _this;
    }
    OneToManyIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var _this = this;
            return __generator(this, function (_a) {
                // This sets this.lastRead to a new Promise right away, as opposed to
                // saying `await this.lastRead; this.lastRead = this.serialNext();` which
                // would not work because this.nextRead would be updated only after the
                // promise resolves.
                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });
                return [2 /*return*/, this.lastRead];
            });
        });
    };
    OneToManyIterator.prototype.serialNext = function () {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        if (!(this.outputQueue.length() === 0)) return [3 /*break*/, 2];
                        return [4 /*yield*/, this.pump()];
                    case 1:
                        // TODO(soergel): consider parallel reads.
                        if (!(_a.sent())) {
                            return [2 /*return*/, { value: null, done: true }];
                        }
                        return [3 /*break*/, 0];
                    case 2: return [2 /*return*/, { value: this.outputQueue.shift(), done: false }];
                }
            });
        });
    };
    return OneToManyIterator;
}(LazyIterator));
exports.OneToManyIterator = OneToManyIterator;
var FlatmapIterator = /** @class */ (function (_super) {
    __extends(FlatmapIterator, _super);
    function FlatmapIterator(upstream, transform) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.transform = transform;
        return _this;
    }
    FlatmapIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> Flatmap";
    };
    FlatmapIterator.prototype.pump = function () {
        return __awaiter(this, void 0, void 0, function () {
            var item, inputTensors, mappedArray, outputTensors, _i, inputTensors_3, t;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, this.upstream.next()];
                    case 1:
                        item = _a.sent();
                        if (item.done) {
                            return [2 /*return*/, false];
                        }
                        inputTensors = tf.tensor_util.getTensorsInContainer(item.value);
                        mappedArray = this.transform(item.value);
                        outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);
                        this.outputQueue.pushAll(mappedArray);
                        // TODO(soergel) faster intersection, and deduplicate outputTensors
                        // TODO(soergel) move to tf.disposeExcept(in, out)?
                        for (_i = 0, inputTensors_3 = inputTensors; _i < inputTensors_3.length; _i++) {
                            t = inputTensors_3[_i];
                            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {
                                t.dispose();
                            }
                        }
                        return [2 /*return*/, true];
                }
            });
        });
    };
    return FlatmapIterator;
}(OneToManyIterator));
/**
 * Provides a `LazyIterator` that concatenates a stream of underlying
 * streams.
 *
 * Doing this in a concurrency-safe way requires some trickery.  In
 * particular, we want this stream to return the elements from the
 * underlying streams in the correct order according to when next() was
 * called, even if the resulting Promises resolve in a different order.
 */
var ChainedIterator = /** @class */ (function (_super) {
    __extends(ChainedIterator, _super);
    function ChainedIterator(iterators, baseErrorHandler) {
        var _this = _super.call(this) || this;
        _this.baseErrorHandler = baseErrorHandler;
        // Strict Promise execution order:
        // a next() call may not even begin until the previous one completes.
        _this.lastRead = null;
        // Local state that should not be clobbered by out-of-order execution.
        _this.iterator = null;
        _this.moreIterators = iterators;
        return _this;
    }
    ChainedIterator.prototype.summary = function () {
        var upstreamSummaries = 'TODO: fill in upstream of chained summaries';
        return upstreamSummaries + " -> Chained";
    };
    ChainedIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                this.lastRead = this.readFromChain(this.lastRead);
                return [2 /*return*/, this.lastRead];
            });
        });
    };
    ChainedIterator.prototype.readFromChain = function (lastRead) {
        return __awaiter(this, void 0, void 0, function () {
            var iteratorResult, itemResult;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: 
                    // Must await on the previous read since the previous read may have advanced
                    // the stream of streams, from which we need to read.
                    // This is unfortunate since we can't parallelize reads. Which means
                    // prefetching of chained streams is a no-op.
                    // One solution is to prefetch immediately upstream of this.
                    return [4 /*yield*/, lastRead];
                    case 1:
                        // Must await on the previous read since the previous read may have advanced
                        // the stream of streams, from which we need to read.
                        // This is unfortunate since we can't parallelize reads. Which means
                        // prefetching of chained streams is a no-op.
                        // One solution is to prefetch immediately upstream of this.
                        _a.sent();
                        if (!(this.iterator == null)) return [3 /*break*/, 3];
                        return [4 /*yield*/, this.moreIterators.next()];
                    case 2:
                        iteratorResult = _a.sent();
                        if (iteratorResult.done) {
                            // No more streams to stream from.
                            return [2 /*return*/, { value: null, done: true }];
                        }
                        this.iterator = iteratorResult.value;
                        if (this.baseErrorHandler != null) {
                            this.iterator = this.iterator.handleErrors(this.baseErrorHandler);
                        }
                        _a.label = 3;
                    case 3: return [4 /*yield*/, this.iterator.next()];
                    case 4:
                        itemResult = _a.sent();
                        if (itemResult.done) {
                            this.iterator = null;
                            return [2 /*return*/, this.readFromChain(lastRead)];
                        }
                        return [2 /*return*/, itemResult];
                }
            });
        });
    };
    return ChainedIterator;
}(LazyIterator));
exports.ChainedIterator = ChainedIterator;
var ZipMismatchMode;
(function (ZipMismatchMode) {
    ZipMismatchMode[ZipMismatchMode["FAIL"] = 0] = "FAIL";
    ZipMismatchMode[ZipMismatchMode["SHORTEST"] = 1] = "SHORTEST";
    ZipMismatchMode[ZipMismatchMode["LONGEST"] = 2] = "LONGEST"; // use nulls for exhausted streams; use up the longest stream.
})(ZipMismatchMode = exports.ZipMismatchMode || (exports.ZipMismatchMode = {}));
/**
 * Provides a `LazyIterator` that zips together an array, dict, or nested
 * structure of `LazyIterator`s (and perhaps additional constants).
 *
 * The underlying streams must provide elements in a consistent order such
 * that they correspond.
 *
 * Typically, the underlying streams should have the same number of
 * elements. If they do not, the behavior is determined by the
 * `mismatchMode` argument.
 *
 * The nested structure of the `iterators` argument determines the
 * structure of elements in the resulting iterator.
 *
 * Doing this in a concurrency-safe way requires some trickery.  In
 * particular, we want this stream to return the elements from the
 * underlying streams in the correct order according to when next() was
 * called, even if the resulting Promises resolve in a different order.
 *
 * @param iterators: An array or object containing LazyIterators at the
 * leaves.
 * @param mismatchMode: Determines what to do when one underlying iterator
 * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)
 * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`
 * causes the zipped iterator to terminate with the furst underlying
 * streams, so elements remaining on the longer streams are ignored.
 * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling
 * in nulls for the exhausted streams, until all streams are exhausted.
 */
var ZipIterator = /** @class */ (function (_super) {
    __extends(ZipIterator, _super);
    function ZipIterator(iterators, mismatchMode) {
        if (mismatchMode === void 0) { mismatchMode = ZipMismatchMode.FAIL; }
        var _this = _super.call(this) || this;
        _this.iterators = iterators;
        _this.mismatchMode = mismatchMode;
        _this.count = 0;
        _this.currentPromise = null;
        return _this;
    }
    ZipIterator.prototype.summary = function () {
        var upstreamSummaries = 'TODO: fill in upstream of zip summaries';
        return "{" + upstreamSummaries + "} -> Zip";
    };
    ZipIterator.prototype.nextState = function (afterState) {
        return __awaiter(this, void 0, void 0, function () {
            function getNext(container) {
                if (container instanceof LazyIterator) {
                    var result = container.next();
                    return {
                        value: result.then(function (x) {
                            numIterators++;
                            if (x.done) {
                                iteratorsDone++;
                            }
                            return x.value;
                        }),
                        recurse: false
                    };
                }
                else {
                    return { value: null, recurse: true };
                }
            }
            var numIterators, iteratorsDone, mapped;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: 
                    // This chaining ensures that the underlying next() are not even called
                    // before the previous ones have resolved.
                    return [4 /*yield*/, afterState];
                    case 1:
                        // This chaining ensures that the underlying next() are not even called
                        // before the previous ones have resolved.
                        _a.sent();
                        numIterators = 0;
                        iteratorsDone = 0;
                        return [4 /*yield*/, deep_map_1.deepMapAndAwaitAll(this.iterators, getNext)];
                    case 2:
                        mapped = _a.sent();
                        if (numIterators === iteratorsDone) {
                            // The streams have all ended.
                            return [2 /*return*/, { value: null, done: true }];
                        }
                        if (iteratorsDone > 0) {
                            switch (this.mismatchMode) {
                                case ZipMismatchMode.FAIL:
                                    throw new Error('Zipped streams should have the same length. ' +
                                        ("Mismatched at element " + this.count + "."));
                                case ZipMismatchMode.SHORTEST:
                                    return [2 /*return*/, { value: null, done: true }];
                                case ZipMismatchMode.LONGEST:
                                default:
                                // Continue.  The exhausted streams already produced value: null.
                            }
                        }
                        this.count++;
                        return [2 /*return*/, { value: mapped, done: false }];
                }
            });
        });
    };
    ZipIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        this.currentPromise = this.nextState(this.currentPromise);
                        return [4 /*yield*/, this.currentPromise];
                    case 1: return [2 /*return*/, (_a.sent())];
                }
            });
        });
    };
    return ZipIterator;
}(LazyIterator));
// Iterators that maintain a ring buffer of pending promises
// ============================================================================
/**
 * A stream that prefetches a given number of items from an upstream source,
 * returning them in FIFO order.
 *
 * Note this prefetches Promises, but makes no guarantees about when those
 * Promises resolve.
 */
var PrefetchIterator = /** @class */ (function (_super) {
    __extends(PrefetchIterator, _super);
    function PrefetchIterator(upstream, bufferSize) {
        var _this = _super.call(this) || this;
        _this.upstream = upstream;
        _this.bufferSize = bufferSize;
        _this.buffer = new ring_buffer_1.RingBuffer(bufferSize);
        return _this;
    }
    PrefetchIterator.prototype.summary = function () {
        return this.upstream.summary() + " -> Prefetch";
    };
    /**
     * Refill the prefetch buffer.  Returns only after the buffer is full, or
     * the upstream source is exhausted.
     */
    PrefetchIterator.prototype.refill = function () {
        while (!this.buffer.isFull()) {
            var v = this.upstream.next();
            this.buffer.push(v);
        }
    };
    PrefetchIterator.prototype.next = function () {
        this.refill();
        // This shift will never throw an error because the buffer is always
        // full after a refill. If the stream is exhausted, the buffer will be
        // full of Promises that will resolve to the end-of-stream signal.
        return this.buffer.shift();
    };
    return PrefetchIterator;
}(LazyIterator));
exports.PrefetchIterator = PrefetchIterator;
/**
 * A stream that performs a sliding-window random shuffle on an upstream
 * source. This is like a `PrefetchIterator` except that the items are
 * returned in randomized order.  Mixing naturally improves as the buffer
 * size increases.
 */
var ShuffleIterator = /** @class */ (function (_super) {
    __extends(ShuffleIterator, _super);
    function ShuffleIterator(upstream, windowSize, seed) {
        var _this = _super.call(this, upstream, windowSize) || this;
        _this.upstream = upstream;
        _this.windowSize = windowSize;
        // Local state that should not be clobbered by out-of-order execution.
        _this.upstreamExhausted = false;
        _this.random = seedrandom.alea(seed || tf.util.now().toString());
        _this.lastRead = Promise.resolve({ value: null, done: false });
        return _this;
    }
    ShuffleIterator.prototype.next = function () {
        return __awaiter(this, void 0, void 0, function () {
            var _this = this;
            return __generator(this, function (_a) {
                // This sets this.lastRead to a new Promise right away, as opposed to
                // saying `await this.lastRead; this.lastRead = this.serialNext();` which
                // would not work because this.nextRead would be updated only after the
                // promise resolves.
                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });
                return [2 /*return*/, this.lastRead];
            });
        });
    };
    ShuffleIterator.prototype.randomInt = function (max) {
        return Math.floor(this.random() * max);
    };
    ShuffleIterator.prototype.chooseIndex = function () {
        return this.randomInt(this.buffer.length());
    };
    ShuffleIterator.prototype.serialNext = function () {
        return __awaiter(this, void 0, void 0, function () {
            var chosenIndex, result;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        // TODO(soergel): consider performance
                        if (!this.upstreamExhausted) {
                            this.refill();
                        }
                        _a.label = 1;
                    case 1:
                        if (!!this.buffer.isEmpty()) return [3 /*break*/, 3];
                        chosenIndex = this.chooseIndex();
                        return [4 /*yield*/, this.buffer.shuffleExcise(chosenIndex)];
                    case 2:
                        result = _a.sent();
                        if (result.done) {
                            this.upstreamExhausted = true;
                        }
                        else {
                            this.refill();
                            return [2 /*return*/, result];
                        }
                        return [3 /*break*/, 1];
                    case 3: return [2 /*return*/, { value: null, done: true }];
                }
            });
        });
    };
    return ShuffleIterator;
}(PrefetchIterator));
exports.ShuffleIterator = ShuffleIterator;
//# sourceMappingURL=lazy_iterator.js.map