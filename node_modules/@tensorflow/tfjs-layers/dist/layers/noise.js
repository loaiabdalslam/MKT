"use strict";
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
var __extends = (this && this.__extends) || (function () {
    var extendStatics = function (d, b) {
        extendStatics = Object.setPrototypeOf ||
            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };
        return extendStatics(d, b);
    };
    return function (d, b) {
        extendStatics(d, b);
        function __() { this.constructor = d; }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
})();
Object.defineProperty(exports, "__esModule", { value: true });
/**
 * TensorFlow.js Layers: Noise Layers.
 */
var tfjs_core_1 = require("@tensorflow/tfjs-core");
var K = require("../backend/tfjs_backend");
var topology_1 = require("../engine/topology");
var types_utils_1 = require("../utils/types_utils");
var GaussianNoise = /** @class */ (function (_super) {
    __extends(GaussianNoise, _super);
    function GaussianNoise(args) {
        var _this = _super.call(this, args) || this;
        _this.supportsMasking = true;
        _this.stddev = args.stddev;
        return _this;
    }
    GaussianNoise.prototype.computeOutputShape = function (inputShape) {
        return inputShape;
    };
    GaussianNoise.prototype.getConfig = function () {
        var baseConfig = _super.prototype.getConfig.call(this);
        var config = { stddev: this.stddev };
        Object.assign(config, baseConfig);
        return config;
    };
    GaussianNoise.prototype.call = function (inputs, kwargs) {
        var _this = this;
        return tfjs_core_1.tidy(function () {
            _this.invokeCallHook(inputs, kwargs);
            var input = types_utils_1.getExactlyOneTensor(inputs);
            var noised = function () {
                return K.randomNormal(input.shape, 0, _this.stddev).add(input);
            };
            var output = K.inTrainPhase(noised, function () { return input; }, kwargs['training'] || false);
            return output;
        });
    };
    GaussianNoise.className = 'GaussianNoise';
    return GaussianNoise;
}(topology_1.Layer));
exports.GaussianNoise = GaussianNoise;
tfjs_core_1.serialization.registerClass(GaussianNoise);
var GaussianDropout = /** @class */ (function (_super) {
    __extends(GaussianDropout, _super);
    function GaussianDropout(args) {
        var _this = _super.call(this, args) || this;
        _this.supportsMasking = true;
        _this.rate = args.rate;
        return _this;
    }
    GaussianDropout.prototype.computeOutputShape = function (inputShape) {
        return inputShape;
    };
    GaussianDropout.prototype.getConfig = function () {
        var baseConfig = _super.prototype.getConfig.call(this);
        var config = { rate: this.rate };
        Object.assign(config, baseConfig);
        return config;
    };
    GaussianDropout.prototype.call = function (inputs, kwargs) {
        var _this = this;
        return tfjs_core_1.tidy(function () {
            _this.invokeCallHook(inputs, kwargs);
            var input = types_utils_1.getExactlyOneTensor(inputs);
            if (_this.rate > 0 && _this.rate < 1) {
                var noised = function () {
                    var stddev = Math.sqrt(_this.rate / (1 - _this.rate));
                    return input.mul(K.randomNormal(input.shape, 1, stddev));
                };
                return K.inTrainPhase(noised, function () { return input; }, kwargs['training'] || false);
            }
            return input;
        });
    };
    GaussianDropout.className = 'GaussianDropout';
    return GaussianDropout;
}(topology_1.Layer));
exports.GaussianDropout = GaussianDropout;
tfjs_core_1.serialization.registerClass(GaussianDropout);
/**
 * Applies Alpha Dropout to the input.
 *
 * As it is a regularization layer, it is only active at training time.
 *
 * Alpha Dropout is a `Dropout` that keeps mean and variance of inputs
 * to their original values, in order to ensure the self-normalizing property
 * even after this dropout.
 * Alpha Dropout fits well to Scaled Exponential Linear Units
 * by randomly setting activations to the negative saturation value.
 *
 * Arguments:
 *   - `rate`: float, drop probability (as with `Dropout`).
 *     The multiplicative noise will have
 *     standard deviation `sqrt(rate / (1 - rate))`.
 *   - `noise_shape`: A 1-D `Tensor` of type `int32`, representing the
 *     shape for randomly generated keep/drop flags.
 *
 * Input shape:
 *   Arbitrary. Use the keyword argument `inputShape`
 *   (tuple of integers, does not include the samples axis)
 *   when using this layer as the first layer in a model.
 *
 * Output shape:
 *   Same shape as input.
 *
 * References:
 *   - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)
 */
var AlphaDropout = /** @class */ (function (_super) {
    __extends(AlphaDropout, _super);
    function AlphaDropout(args) {
        var _this = _super.call(this, args) || this;
        _this.supportsMasking = true;
        _this.rate = args.rate;
        _this.noiseShape = args.noiseShape;
        return _this;
    }
    AlphaDropout.prototype._getNoiseShape = function (inputs) {
        return this.noiseShape || types_utils_1.getExactlyOneTensor(inputs).shape;
    };
    AlphaDropout.prototype.computeOutputShape = function (inputShape) {
        return inputShape;
    };
    AlphaDropout.prototype.getConfig = function () {
        var baseConfig = _super.prototype.getConfig.call(this);
        var config = { rate: this.rate };
        Object.assign(config, baseConfig);
        return config;
    };
    AlphaDropout.prototype.call = function (inputs, kwargs) {
        var _this = this;
        return tfjs_core_1.tidy(function () {
            if (_this.rate < 1 && _this.rate > 0) {
                var noiseShape_1 = _this._getNoiseShape(inputs);
                var droppedInputs = function () {
                    var input = types_utils_1.getExactlyOneTensor(inputs);
                    var alpha = 1.6732632423543772848170429916717;
                    var scale = 1.0507009873554804934193349852946;
                    var alphaP = -alpha * scale;
                    var keptIdx = tfjs_core_1.greaterEqual(tfjs_core_1.randomUniform(noiseShape_1), _this.rate);
                    keptIdx = K.cast(keptIdx, 'float32'); // get default dtype.
                    // Get affine transformation params.
                    var a = Math.pow(((1 - _this.rate) * (1 + _this.rate * Math.pow(alphaP, 2))), -0.5);
                    var b = -a * alphaP * _this.rate;
                    // Apply mask.
                    var x = input.mul(keptIdx).add(keptIdx.add(-1).mul(alphaP));
                    return x.mul(a).add(b);
                };
                return K.inTrainPhase(droppedInputs, function () { return types_utils_1.getExactlyOneTensor(inputs); }, kwargs['training'] || false);
            }
            return inputs;
        });
    };
    AlphaDropout.className = 'AlphaDropout';
    return AlphaDropout;
}(topology_1.Layer));
exports.AlphaDropout = AlphaDropout;
tfjs_core_1.serialization.registerClass(AlphaDropout);
//# sourceMappingURL=noise.js.map